{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show me the money!üí∏\n",
    "# ¬°Ense√±ame la Pasta!üí∏\n",
    "## La Batalla Anal√≠tica bancaria üí∏üìä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "¬°Prep√°rate para sumergirte en el fascinante mundo de los pr√©stamos bancarios con un grito audaz: \"¬°Ense√±ame la Pasta!\" Esta competici√≥n desafiar√° tus habilidades anal√≠ticas mientras te sumerges en conjuntos de datos intrigantes y navegas por las olas financieras.\n",
    "\n",
    "üí° Desaf√≠o Anal√≠tico: Tu misi√≥n es desentra√±ar los secretos detr√°s de cada solicitud de pr√©stamo. Descubre patrones, identifica oportunidades y muestra al mundo que tienes lo necesario para destacar en la batalla anal√≠tica.\n",
    "\n",
    "üèÅ Carrera hacia la Precisi√≥n: Enfr√©ntate a la competencia y demuestra que tu modelo puede superar las decisiones humanas. ¬øPuedes prever qui√©n merece un pr√©stamo y qui√©n noü§∑‚Äç‚ôÇÔ∏è? ¬°La carrera hacia la precisi√≥n est√° en marcha!\n",
    "\n",
    "¬°Mucha suerte en la batalla! ü¶æ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "Tal y como sucede en otras competiciones de Kaggle, deber√©is centraros en disponer un buen modelo basado en el conjunto de datos de entrenamiento (train.csv) y ver si gracias al buen trabajo realizado obten√©is una buena predicci√≥n sobre el conjunto de evaluaci√≥n (test.csv). No dispondr√©is de las clasificaciones asociadas al conjunto de set con lo que hasta no subir vuestros datos a la plataforma no sabr√©is c√≥mo de bueno es vuestro modelo en realidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "En esta competici√≥n, evaluaremos la eficacia de los modelos utilizando la m√©trica Area Under Curve (AUC). Esta m√©trica proporciona una medida de la capacidad del modelo para discriminar entre clases, siendo especialmente relevante en problemas de clasificaci√≥n binaria.\n",
    "\n",
    "Para obtener m√°s detalles sobre la interpretaci√≥n y aplicaci√≥n de AUC, te recomendamos explorar el siguiente enlace: Understanding AUC-ROC Curve. Este recurso proporcionar√° una comprensi√≥n m√°s profunda de c√≥mo se utiliza AUC para evaluar y comparar el rendimiento de los modelos en esta competici√≥n. ¬°Explora y prep√°rate para destacar en la puntuaci√≥n AUC! üìäüéØ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = pd.read_csv('./data/train.csv')\n",
    "dte = pd.read_csv('./data/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.dropna(inplace=True)\n",
    "\n",
    "# median_values = dtr.median()\n",
    "# dtr = dtr.fillna(median_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA TRAINING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on ENSEMBLING Exercise????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dtr.drop('SeriousDlqin2yrs', axis=1)\n",
    "y = dtr['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scal = scaler.fit_transform(X_train)\n",
    "X_test_scal = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_r = LogisticRegression()\n",
    "\n",
    "log_r.fit(X_train_scal, y_train)\n",
    "\n",
    "y_pred = log_r.predict(X_test_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_r.score(X_test_scal, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred, normalize='true'), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y_pred_prob = log_r.predict_proba(X_test_scal)\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_pred_prob[:,1])\n",
    "pd.DataFrame({\"tpr\":tpr, \"fpr\":fpr, \"threshold\":threshold})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "plt.xlabel(\"Ratio de falsos positivos\")\n",
    "plt.ylabel(\"Ratio de verdaderos positivos\")\n",
    "plt.title(\"Curva ROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_pred_prob[:,1])\n",
    "pd.DataFrame({\"prec\":prec[1:], \"rec\":rec[1:], \"threshold\":thresholds})[80:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rec, prec)\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "\n",
    "plt.title(\"PR Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dte.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dte.dropna(inplace=True)\n",
    "\n",
    "# median_values = dte.median()\n",
    "# dte = dte.fillna(median_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dte.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dte.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dte = dte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_dte_scal = scaler.fit_transform(X_dte)\n",
    "\n",
    "y_dte = log_r.predict(X_dte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dte = pd.DataFrame(y_dte, columns=['SeriousDlqin2yrs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dte.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsol = pd.DataFrame()\n",
    "dsol['ID'] = dte['ID']\n",
    "dsol['SeriousDlqin2yrs'] = y_dte['SeriousDlqin2yrs']\t\n",
    "dsol.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Construct the filename\n",
    "filename = f\"submission_dgerwig_{current_datetime.strftime('%Y_%m_%d__%H_%M')}.csv\"\n",
    "\n",
    "# Directory where the file will be saved\n",
    "directory = \"submissions\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Full path for the file\n",
    "filepath = os.path.join(directory, filename)\n",
    "\n",
    "dsol.to_csv(filepath, index=False)\n",
    "\n",
    "print(f\"‚úÖ File '{filepath}' generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
