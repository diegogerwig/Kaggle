{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laptops market ðŸ’»\n",
    "# Precio PortÃ¡tiles ðŸ’»\n",
    "## Veamos cÃ³mo de buenos somos prediciendo el valor de los productos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "Nuestro jefe estaba buscando un@s maquinas para obtener datos de la competencia y poder aplicarle los conocimientos obtenidos para asignar precios a nuestra tienda de \"MERIMARKT\".\n",
    "Lamentablemente se habÃ­an ido de vacaciones y nos lo ha pedido a nosotr@s â€¦\n",
    "ðŸ’¥ðŸª“ðŸ”ª\n",
    "\n",
    "Nos toca arremangarnos las mangas y aplicar los conocimientos obtenidos en ML para obtener un modelo de predicciÃ³n de precios de portÃ¡tiles en funciÃ³n de sus marcas y prestaciones para poder lanzarlos a un precio competitivo al mercado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "En esta tarea, utilizaremos el error absoluto medio (MAE) para evaluar la eficacia del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error, root_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data.rename(columns={'price_euros' : 'price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.get_dummies(data['company'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object = 'company'\n",
    "data = pd.concat([data, pd.get_dummies(data[data_object], prefix=data_object, dtype=int)], axis=1)\n",
    "data.drop(columns=[data_object], inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object = 'product'\n",
    "data.drop(columns=[data_object], inplace=True)\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object = 'typename'\n",
    "data = pd.concat([data, pd.get_dummies(data[data_object], prefix=data_object, dtype=int)], axis=1)\n",
    "data.drop(columns=[data_object], inplace=True)\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_screen_resolution(resolution):\n",
    "    result = {\n",
    "        'screen_4K': 0,  \n",
    "        'screen_HD': 0,\n",
    "        'screen_Touchscreen': 0,  \n",
    "        'screen_Retina': 0,\n",
    "        'screen_Ultra': 0,\n",
    "        'screen_width': None,  \n",
    "        'screen_height': None\n",
    "    }\n",
    "\n",
    "    if '4K' in resolution:\n",
    "        result['screen_4K'] = 1  \n",
    "    if 'Full HD' in resolution or 'HD' in resolution:\n",
    "        result['screen_HD'] = 1\n",
    "    if 'Retina' in resolution:\n",
    "        result['screen_Retina'] = 1\n",
    "    \n",
    "    match = re.search(r'(\\d{3,4})x(\\d{3,4})', resolution)\n",
    "    if match:\n",
    "        width, height = match.groups()\n",
    "        result['screen_width'] = int(width)\n",
    "        result['screen_height'] = int(height)\n",
    "\n",
    "    return result\n",
    "\n",
    "data_screen = data['screenresolution'].apply(process_screen_resolution)\n",
    "\n",
    "data_screen = pd.DataFrame(data_screen.tolist())\n",
    "\n",
    "data = pd.concat([data, data_screen], axis=1)\n",
    "\n",
    "data.drop(columns=['screenresolution'], inplace=True)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cpu_info(cpu_string):\n",
    "    cpu_intel = 0\n",
    "    cpu_amd = 0\n",
    "    cpu_ghz = None\n",
    "\n",
    "    if 'Intel' in cpu_string:\n",
    "        cpu_intel = 1\n",
    "        match = re.search(r'(\\d+\\.?\\d*)GHz', cpu_string)\n",
    "        if match:\n",
    "            cpu_ghz = float(match.group(1))\n",
    "    \n",
    "    if 'AMD' in cpu_string:\n",
    "        cpu_amd = 1\n",
    "        match = re.search(r'(\\d+\\.?\\d*)GHz', cpu_string)\n",
    "        if match:\n",
    "            cpu_ghz = float(match.group(1))\n",
    "\n",
    "    return pd.Series([cpu_intel, cpu_amd, cpu_ghz], index=['cpu_intel', 'cpu_amd', 'cpu_ghz'])\n",
    "\n",
    "data[['cpu_intel', 'cpu_amd', 'cpu_ghz']] = data['cpu'].apply(extract_cpu_info)\n",
    "\n",
    "data['cpu_intel'] = data['cpu_intel'].astype(int)\n",
    "data['cpu_amd'] = data['cpu_amd'].astype(int)\n",
    "\n",
    "data.drop(columns=['cpu'], inplace=True)\n",
    "\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ram(ram_string):\n",
    "    match = re.search(r'(\\d+)GB', ram_string)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "data['ram_numeric'] = data['ram'].apply(extract_ram)\n",
    "\n",
    "data.drop(columns=['ram'], inplace=True)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_memory_info(memory_string):\n",
    "    memory_types = {\n",
    "        'memory_HDD': 0,\n",
    "        'memory_SSD': 0,\n",
    "        'memory_Flash': 0\n",
    "    }\n",
    "    memory_sizes = {    \n",
    "        'memory_HDD_GB': 0,\n",
    "        'memory_SSD_GB': 0,\n",
    "        'memory_Flash_GB': 0\n",
    "    }\n",
    "    \n",
    "    matches = re.findall(r'(\\d+)([A-Za-z ]+)', memory_string)\n",
    "    \n",
    "    for match in matches:\n",
    "        size = int(match[0])\n",
    "        unit = match[1].strip().upper()\n",
    "        \n",
    "        if 'TB' in unit:\n",
    "            size *= 1000  \n",
    "        \n",
    "        if 'HDD' in unit:\n",
    "            memory_types['memory_HDD'] = 1\n",
    "            memory_sizes['memory_HDD_GB'] += size\n",
    "        elif 'SSD' in unit:\n",
    "            memory_types['memory_SSD'] = 1\n",
    "            memory_sizes['memory_SSD_GB'] += size\n",
    "        elif 'FLASH STORAGE' in unit:\n",
    "            memory_types['memory_Flash'] = 1\n",
    "            memory_sizes['memory_Flash_GB'] += size\n",
    "    \n",
    "    result = {**memory_types, **memory_sizes}\n",
    "    return pd.Series(result)\n",
    "\n",
    "data[['memory_HDD', 'memory_SSD', 'memory_Flash', 'memory_HDD_GB', 'memory_SSD_GB', 'memory_Flash_GB']] = data['memory'].apply(extract_memory_info)\n",
    "\n",
    "data.drop(columns=['memory'], inplace=True)\n",
    "\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object = 'gpu'\n",
    "# data = pd.concat([data, pd.get_dummies(data[data_object], prefix=data_object, dtype=int)], axis=1)\n",
    "data.drop(columns=[data_object], inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object = 'opsys'\n",
    "data = pd.concat([data, pd.get_dummies(data[data_object], prefix=data_object, dtype=int)], axis=1)\n",
    "data.drop(columns=[data_object], inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weight(weight_string):\n",
    "    match = re.search(r'(\\d+(\\.\\d+)?)', weight_string)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return None\n",
    "\n",
    "data['weight_kg'] = data['weight'].apply(extract_weight)\n",
    "\n",
    "data.drop(columns=['weight'], inplace=True)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(data.columns)\n",
    "\n",
    "index_inches = columns.index('inches')\n",
    "index_price = columns.index('price')\n",
    "\n",
    "columns[index_inches], columns[index_price] = columns[index_price], columns[index_inches]\n",
    "\n",
    "data = data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['company_Fujitsu', 'company_Mediacom', 'opsys_Android']\n",
    "data = data.drop(features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('price', axis=1)\n",
    "y = data['price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# X_df = pd.DataFrame(X, columns=data.columns[1:])\n",
    "# X_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train:', X_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test:', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = model.predict(X_test)\n",
    "\n",
    "print(predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object = 'company'\n",
    "data_test = pd.concat([data_test, pd.get_dummies(data_test[data_object], prefix=data_object, dtype=int)], axis=1)\n",
    "data_test.drop(columns=[data_object], inplace=True)\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object = 'product'\n",
    "data_test.drop(columns=[data_object], inplace=True)\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object = 'typename'\n",
    "data_test = pd.concat([data_test, pd.get_dummies(data_test[data_object], prefix=data_object, dtype=int)], axis=1)\n",
    "data_test.drop(columns=[data_object], inplace=True)\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_screen_resolution(resolution):\n",
    "    result = {\n",
    "        'screen_4K': 0,  \n",
    "        'screen_HD': 0,\n",
    "        'screen_Touchscreen': 0,  \n",
    "        'screen_Retina': 0,\n",
    "        'screen_Ultra': 0,\n",
    "        'screen_width': None,  \n",
    "        'screen_height': None\n",
    "    }\n",
    "\n",
    "    if '4K' in resolution:\n",
    "        result['screen_4K'] = 1  \n",
    "    if 'Full HD' in resolution or 'HD' in resolution:\n",
    "        result['screen_HD'] = 1\n",
    "    if 'Retina' in resolution:\n",
    "        result['screen_Retina'] = 1\n",
    "    \n",
    "    match = re.search(r'(\\d{3,4})x(\\d{3,4})', resolution)\n",
    "    if match:\n",
    "        width, height = match.groups()\n",
    "        result['screen_width'] = int(width)\n",
    "        result['screen_height'] = int(height)\n",
    "\n",
    "    return result\n",
    "\n",
    "data_screen = data_test['screenresolution'].apply(process_screen_resolution)\n",
    "\n",
    "data_screen = pd.DataFrame(data_screen.tolist())\n",
    "\n",
    "data_test = pd.concat([data_test, data_screen], axis=1)\n",
    "\n",
    "data_test.drop(columns=['screenresolution'], inplace=True)\n",
    "\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cpu_info(cpu_string):\n",
    "    cpu_intel = 0\n",
    "    cpu_amd = 0\n",
    "    cpu_ghz = None\n",
    "\n",
    "    if 'Intel' in cpu_string:\n",
    "        cpu_intel = 1\n",
    "        match = re.search(r'(\\d+\\.?\\d*)GHz', cpu_string)\n",
    "        if match:\n",
    "            cpu_ghz = float(match.group(1))\n",
    "    \n",
    "    if 'AMD' in cpu_string:\n",
    "        cpu_amd = 1\n",
    "        match = re.search(r'(\\d+\\.?\\d*)GHz', cpu_string)\n",
    "        if match:\n",
    "            cpu_ghz = float(match.group(1))\n",
    "\n",
    "    return pd.Series([cpu_intel, cpu_amd, cpu_ghz], index=['cpu_intel', 'cpu_amd', 'cpu_ghz'])\n",
    "\n",
    "data_test[['cpu_intel', 'cpu_amd', 'cpu_ghz']] = data_test['cpu'].apply(extract_cpu_info)\n",
    "\n",
    "data_test['cpu_intel'] = data_test['cpu_intel'].astype(int)\n",
    "data_test['cpu_amd'] = data_test['cpu_amd'].astype(int)\n",
    "\n",
    "data_test.drop(columns=['cpu'], inplace=True)\n",
    "\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ram(ram_string):\n",
    "    match = re.search(r'(\\d+)GB', ram_string)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "data_test['ram_numeric'] = data_test['ram'].apply(extract_ram)\n",
    "\n",
    "data_test.drop(columns=['ram'], inplace=True)\n",
    "\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_memory_info(memory_string):\n",
    "    memory_types = {\n",
    "        'memory_HDD': 0,\n",
    "        'memory_SSD': 0,\n",
    "        'memory_Flash': 0\n",
    "    }\n",
    "    memory_sizes = {    \n",
    "        'memory_HDD_GB': 0,\n",
    "        'memory_SSD_GB': 0,\n",
    "        'memory_Flash_GB': 0\n",
    "    }\n",
    "    \n",
    "    matches = re.findall(r'(\\d+)([A-Za-z ]+)', memory_string)\n",
    "    \n",
    "    for match in matches:\n",
    "        size = int(match[0])\n",
    "        unit = match[1].strip().upper()\n",
    "        \n",
    "        if 'TB' in unit:\n",
    "            size *= 1000  \n",
    "        \n",
    "        if 'HDD' in unit:\n",
    "            memory_types['memory_HDD'] = 1\n",
    "            memory_sizes['memory_HDD_GB'] += size\n",
    "        elif 'SSD' in unit:\n",
    "            memory_types['memory_SSD'] = 1\n",
    "            memory_sizes['memory_SSD_GB'] += size\n",
    "        elif 'FLASH STORAGE' in unit:\n",
    "            memory_types['memory_Flash'] = 1\n",
    "            memory_sizes['memory_Flash_GB'] += size\n",
    "    \n",
    "    result = {**memory_types, **memory_sizes}\n",
    "    return pd.Series(result)\n",
    "\n",
    "data_test[['memory_HDD', 'memory_SSD', 'memory_Flash', 'memory_HDD_GB', 'memory_SSD_GB', 'memory_Flash_GB']] = data_test['memory'].apply(extract_memory_info)\n",
    "\n",
    "data_test.drop(columns=['memory'], inplace=True)\n",
    "\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object = 'gpu'\n",
    "# data = pd.concat([data, pd.get_dummies(data[data_object], prefix=data_object, dtype=int)], axis=1)\n",
    "data_test.drop(columns=[data_object], inplace=True)\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object = 'opsys'\n",
    "data_test = pd.concat([data_test, pd.get_dummies(data_test[data_object], prefix=data_object, dtype=int)], axis=1)\n",
    "data_test.drop(columns=[data_object], inplace=True)\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weight(weight_string):\n",
    "    match = re.search(r'(\\d+(\\.\\d+)?)', weight_string)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return None\n",
    "\n",
    "data_test['weight_kg'] = data_test['weight'].apply(extract_weight)\n",
    "\n",
    "data_test.drop(columns=['weight'], inplace=True)\n",
    "\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_copy = data_test.drop('id', axis=1)\n",
    "# features = ['company_Fujitsu', 'company_Mediacom', 'opsys_Android']\n",
    "# for feature in features:\n",
    "#     if feature not in data_test.columns:\n",
    "#         data_test[feature] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test_copy\n",
    "\n",
    "X_test = X_test.dropna()\n",
    "\n",
    "X_test.info()\n",
    "\n",
    "X_test.describe()\n",
    "\n",
    "predicciones = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['ID'] = data_test['id']\n",
    "df2 = pd.DataFrame(predicciones, columns=['Price_euros'])\n",
    "df = pd.concat([df, df2], axis=1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Construct the filename\n",
    "filename = f\"submission_dgerwig_{current_datetime.strftime('%Y_%m_%d__%H_%M')}.csv\"\n",
    "\n",
    "# Directory where the file will be saved\n",
    "directory = \"submissions\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Full path for the file\n",
    "filepath = os.path.join(directory, filename)\n",
    "\n",
    "\n",
    "df.to_csv(filepath, index=False)\n",
    "\n",
    "\n",
    "print(f\"âœ… File '{filepath}' generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUATE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SUBMMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def get_most_recent_file(directory):\n",
    "    # Ensure the directory path uses the correct separator\n",
    "    directory = os.path.abspath(directory)\n",
    "    files = glob.glob(os.path.join(directory, \"*\"))\n",
    "    if not files:\n",
    "        return None\n",
    "    return max(files, key=os.path.getmtime)\n",
    "\n",
    "directory = \"./submissions\"\n",
    "most_recent_file = get_most_recent_file(directory)\n",
    "\n",
    "if most_recent_file is None:\n",
    "    print(\"No files found in the submissions directory.\")\n",
    "else:\n",
    "    print(f\"Most recent file: {most_recent_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
